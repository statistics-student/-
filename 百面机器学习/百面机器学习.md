# 百面机器学习

## 损失函数

+ 平方损失
+ 交叉熵损失（逻辑回归与softmax分类）
+ 指数损失（adboost）
+ 0-1损失（感知机）
+ Huber损失
+ 合页损失（支持向量机）
+ 正则损失（防止梯度爆炸和过拟合）

##降维

### PCA

样本协方差矩阵进行特征值分解，得到特征值最大前d个特征向量

###LDA（线性判别分析）

**假设**：高斯分布，各个类协方差相等

最大化类间距离和最小化类内距离$\implies$$w=S_w^{-1}(\mu_1-\mu_2)$,$w$是投影方向，所以最终$w$由样本均值和类内方差决定。

对矩阵$S_w^{-1}S_b$进行特征值分解，$S_b=S_t-S_w$,$S_w$是类内散度矩阵,$S_t$是全局散度矩阵,$S_w=\sum_{x\in{C_i}}(x-\mu_i)(x-\mu_i)^T$,$S_t=\sum_{i=1}(x-\mu_i)(x-\mu_i)^T$

<font color=red face='微软雅黑'>**LDA是有监督降维，PCA是无监督降维**</font>

**example1**:

:a:提取个人的语音信号：数据降噪$\implies$PCA降维

:b:一段音频区分属于哪个人：是每个语音信号具有区分性$\implies$LDA降维

**example2**:

PCA得到特征脸不具有区分性，LDA得到特征脸具有区分性

## 非监督学习

### K均值

**代价函数**：各个样本距离所属簇中心点的误差平方和

$$J(c,\mu)=\sum_{i=1}^M||x_i-\mu_i||^2$$

**缺点**：受初值和离群点影导致容易局部最优而不是全局最优，不太适应几类样本方差比较大的情况

**优点**：对于大数据集可伸缩和高效

<font color=red>**计算复杂度**</font>：$O(NKt)$,N样本数，K是聚类簇数，t是迭代轮数

**步骤**：

![](E:\笔记系列\百面机器学习\图片\K均值步骤.PNG)

**调优**：

+ 数据归一化和离群点处理

+ 合理选择K值

  + 手肘法

  + Gap Statistic

    随机样本的损失与实际样本的损失差越小的K，也就是GAP(K)值最大时的K值

+ 核函数

  当非凸时

**改进**：

+ K-means++

  选取第n个聚类中心时，下一个中心离前n个越远的距离越大

+ ISODATA

  + 样本点太少的簇删除$\implies$ 合并操作
  + 样本数据点过多，较分散$\implies$分散操作

**收敛证明**：EM算法

### 高斯混合模型

利用多个高斯分布的线性组合来对数据拟合

**收敛证明**：EM算法

### 自组织神经映射网络（SOM）

**特点**：无监督

**作用**：

+ 聚类
+ 高维可视化
+ 数据压缩
+ 特征提取

**结构**：

+ 输入层
+ 隐藏层
+ 输出层$\implies$ 拓扑关系的，一维线阵，二维平面阵，三维栅格阵（少见）

**原理**：

输出层神经元个数通常是聚类个数，样本激活的神经元则属于的聚类中心，根据最小判别函数值激活的特定神经元更新参数，临近的也更新，越远的神经元更新程度减小，重复上述过程

<font color=red>本质上是一种拓扑映射</font>

### 聚类算法的评估

#### 常见数据簇

+ 以中心定义的数据簇
+ 以密度定义的数据簇
+ 以联通定义的数据簇
+ 以概念定义的数据簇

#### 聚类评估任务

1. 估计聚类趋势

   霍普金斯统计量判断数据在空间上的随机性，越随机H值越接近0.5，聚类趋势越明显，越接近1

2. 判定数据簇数

   + 手肘法

   + Gap Statistic

3. 测定聚类质量

   考察簇的分离情况与紧凑情况

   常见的度量指标：

   + 轮廓系数
   + 均方根标准偏差
   + R方
   + 改进的$Hubert\Gamma$统计

## 概率图模型

+ 贝叶斯网络：有向图
+ 马尔可夫网络：无向图

:a:朴素贝叶斯

:b:最大熵

:black_joker:隐马尔科夫

:blue_book:条件随机场

:artificial_satellite:主题模型

### 生成式模型和判别式模型

**<font color='green'>生成式：联合概率$\implies$ 边缘分布</font>**

**<font color='green'>判别式：条件概率$\implies$ 消除隐含变量</font>**

####生成式模型

+ 判别式分析（LDA）
+ 朴素贝叶斯
+ K近邻(KNN)
+ 混合高斯模型
+ 马尔科夫模型(HMM)
+ 贝叶斯网络
+ Sigmoid Belief Networks
+ 马尔科夫随机场(Markov Random Fields)
+ 深度信念网络(DBN)

#### 判别式模型

+ 线性回归(Linear Regression)
+ 逻辑斯蒂回归(Logistic Regression)
+ 神经网络(NN)
+ 支持向量机(SVM)
+ 高斯过程(Gaussian Process)
+ 条件随机场(CRF)
+ CART(Classification and Regression Tree)

### 主题模型

+ pLSA

  利用生成模型来建模文章的生成过程

  利用最大期望算法求解

+ LDA

  与pLSA基本一致，可以看作pLSA的贝叶斯版本，不同的是为主题分布和词分布分别加了两个迪利克雷先验

## 深度学习

### 卷积神经网络

####参数共享

#### 池化

+ 均值池化

  对背景的保留效果较好

+ 最大池化

  更好地提取纹理

<font color=red>**本质**：降采样</font>

**作用**

能够保持对平移、伸缩、旋转操作的不变性

