# 百面机器学习

## 损失函数

+ 平方损失
+ 交叉熵损失（逻辑回归与softmax分类）
+ 指数损失（adboost）
+ 0-1损失（感知机）
+ Huber损失
+ 合页损失（支持向量机）
+ 正则损失（防止梯度爆炸和过拟合）

##降维

### PCA

样本协方差矩阵进行特征值分解，得到特征值最大前d个特征向量

###LDA（线性判别分析）

**假设**：高斯分布，各个类协方差相等

最大化类间距离和最小化类内距离$\implies$$w=S_w^{-1}(\mu_1-\mu_2)$,$w$是投影方向，所以最终$w$由样本均值和类内方差决定。

对矩阵$S_w^{-1}S_b$进行特征值分解，$S_b=S_t-S_w$,$S_w$是类内散度矩阵,$S_t$是全局散度矩阵,$S_w=\sum_{x\in{C_i}}(x-\mu_i)(x-\mu_i)^T$,$S_t=\sum_{i=1}(x-\mu_i)(x-\mu_i)^T$

<font color=red face='微软雅黑'>**LDA是有监督降维，PCA是无监督降维**</font>

**example1**:

:a:提取个人的语音信号：数据降噪$\implies$PCA降维

:b:一段音频区分属于哪个人：是每个语音信号具有区分性$\implies$LDA降维

**example2**:

PCA得到特征脸不具有区分性，LDA得到特征脸具有区分性

## 非监督学习

### K均值

**代价函数**：各个样本距离所属簇中心点的误差平方和

$$J(c,\mu)=\sum_{i=1}^M||x_i-\mu_i||^2$$

**缺点**：受初值和离群点影导致容易局部最优而不是全局最优，不太适应几类样本方差比较大的情况

**优点**：对于大数据集可伸缩和高效

<font color=red>**计算复杂度**</font>：$O(NKt)$,N样本数，K是聚类簇数，t是迭代轮数

**步骤**：

![](E:\笔记系列\百面机器学习\图片\K均值步骤.PNG)

**调优**：

+ 数据归一化和离群点处理

+ 合理选择K值

  + 手肘法

  + Gap Statistic

    随机样本的损失与实际样本的损失差越小的K，也就是GAP(K)值最大时的K值

+ 核函数

  当非凸时

**改进**：

+ K-means++

  选取第n个聚类中心时，下一个中心离前n个越远的距离越大

+ ISODATA

  + 样本点太少的簇删除$\implies$ 合并操作
  + 样本数据点过多，较分散$\implies$分散操作

**收敛证明**：EM算法

### 高斯混合模型

利用多个高斯分布的线性组合来对数据拟合

**收敛证明**：EM算法

### 自组织神经映射网络（SOM）

**特点**：无监督

**作用**：

+ 聚类
+ 高维可视化
+ 数据压缩
+ 特征提取

**结构**：

+ 输入层
+ 隐藏层
+ 输出层$\implies$ 拓扑关系的，一维线阵，二维平面阵，三维栅格阵（少见）

**原理**：

输出层神经元个数通常是聚类个数，样本激活的神经元则属于的聚类中心，根据最小判别函数值激活的特定神经元更新参数，临近的也更新，越远的神经元更新程度减小，重复上述过程

<font color=red>本质上是一种拓扑映射</font>

### 聚类算法的评估

#### 常见数据簇

+ 以中心定义的数据簇
+ 以密度定义的数据簇
+ 以联通定义的数据簇
+ 以概念定义的数据簇

#### 聚类评估任务

1. 估计聚类趋势

   霍普金斯统计量判断数据在空间上的随机性，越随机H值越接近0.5，聚类趋势越明显，越接近1

2. 判定数据簇数

   + 手肘法

   + Gap Statistic

3. 测定聚类质量

   考察簇的分离情况与紧凑情况

   常见的度量指标：

   + 轮廓系数
   + 均方根标准偏差
   + R方
   + 改进的$Hubert\Gamma$统计

## 概率图模型

+ 贝叶斯网络：有向图
+ 马尔可夫网络：无向图

:a:朴素贝叶斯

:b:最大熵

:black_joker:隐马尔科夫

:blue_book:条件随机场

:artificial_satellite:主题模型

### 生成式模型和判别式模型

**<font color='green'>生成式：联合概率$\implies$ 边缘分布</font>**

**<font color='green'>判别式：条件概率$\implies$ 消除隐含变量</font>**

####生成式模型

+ 判别式分析（LDA）
+ 朴素贝叶斯
+ K近邻(KNN)
+ 混合高斯模型
+ 马尔科夫模型(HMM)
+ 贝叶斯网络
+ Sigmoid Belief Networks
+ 马尔科夫随机场(Markov Random Fields)
+ 深度信念网络(DBN)

#### 判别式模型

+ 线性回归(Linear Regression)
+ 逻辑斯蒂回归(Logistic Regression)
+ 神经网络(NN)
+ 支持向量机(SVM)
+ 高斯过程(Gaussian Process)
+ 条件随机场(CRF)
+ CART(Classification and Regression Tree)

### 主题模型

+ pLSA

  利用生成模型来建模文章的生成过程

  利用最大期望算法求解

+ LDA

  与pLSA基本一致，可以看作pLSA的贝叶斯版本，不同的是为主题分布和词分布分别加了两个迪利克雷先验

## 深度学习

### 卷积神经网络

####参数共享

#### 池化

+ 均值池化

  对背景的保留效果较好

+ 最大池化

  更好地提取纹理

<font color=red>**本质**：降采样</font>

**作用**

能够保持对平移、伸缩、旋转操作的不变性

## 集成学习

+ Boosting

  串行的方式,不断给予上层基分类器分错样本的权重

  <font color=red>聚焦于基分类器分错的样本,减小集成分类器的偏差</font>

+ Bagging

  各基分类器之间无强依赖,并行训练,最后通过投票的方式进行决策

  <font color=red>通过综合,来减小集成分类器的方差</font>

  example:随机森林,(有放回抽样,各子集之间有可能重叠)

  bagging算法示意图

  ![](E:\笔记系列\百面机器学习\图片\bagging算法示意图.PNG)

**<font color=red>偏差和方差</font>**

<font color=green>偏差主要由于分类器的表达能力有限导致系统性错误,表现在训练误差不收敛</font>

<font color=green>方差主要由于分类器对于样本分布过于敏感,导致在训练样本较少时产生过拟合</font>

### 集成学习的步骤

一般分为以下3个步骤

1. 找到误差相互独立的基分类器

2. 训练基分类器

3. 合并基分类器的结果

   合并基分类器的方法:

   + voting
   + stacking(串行),一般结果相加或者以基分类器作为特征,用逻辑回归等更复杂的算法进行融合

**example**

<font color=red>Adaboost</font>

1. 确定基分类器(如ID3,树形模型由于结构简单且较易产生随机性所以比较常用)

2. 训练基分类器

   假设训练集为$\{x_i,y_i\},i=1,\cdots,N$,其中$y_i\in\{-1,1\}$,并且有T个基分类器,则可以按照以下流程训练

   ![](E:\笔记系列\百面机器学习\图片\adboost步骤.PNG)

3. 合并基分类器

   加权投票的结果为:$\operatorname { sign } \left( \sum _ { t = 1 } ^ { T } h _ { t } ( z ) a _ { t } \right)$

<font color=red>GBDT</font>

基于残差去学习

例如用户A的真实年龄是25岁，但第一棵决策树的预测年龄是22岁，差了3岁，即残差为3。那么在第二棵树里我们把A的年龄设为3岁去学习，如果第二棵树能把A分到3岁的叶子节点，那两棵树的结果相加就可以得到A的真实年龄；如果第二棵树的结论是5岁，则A仍然存在-2岁的残差，第三棵树里A的年龄就变成-2岁，继续学。这里使用残差继续学习，就是GBDT中Gradient Boosted所表达的意思。

### 基分类器

+ 决策树

  <font color=red>优点:</font>

  1. 方便将权重整合到训练中,而不需要采取过采样的方式调整样本权重
  2. 表达能力和泛化能力可以通过调节树的层数来折中
  3. 决策树属于"不稳定学习器",容易受样本干扰和节点分裂时随机选择特征,**神经网络**也属于这一类

**<font color=green>随机森林的基分类器不能被替换为线性基分类器和K近邻,因为后者属于稳定的学习器,而且bagging的抽样方式可能导致训练更难收敛</font>**

### 偏差与方差

<font color=red>**偏差**</font>

偏差指的是由所有采样得到的大小为m的训练数据集训练出的所有模型的**输出的平均值和真实模型输出之间的偏差。**

<font color=red>由偏差带来的误差通常在训练误差上就能体现出来。</font>

<font color=red>**方差**</font>

方差指的是由所有采样得到的大小为m的训练数据集训练出的所有模型的输出的方差。方差通常是由于模型的复杂度相对于训练样本数m过高导致的，比如一共有100个训练样本，而我们假设模型是阶数不大于200的多项式函数。由方差带来的误差通常体现在测试误差相对于训练误差的增量上。

![](E:\笔记系列\百面机器学习\图片\偏差与方差示意图.PNG)

###bagging和boosting

<font color=red>如何从减小方差和偏差的角度解释Boosting 和Bagging的原理？</font>

简单回答这个问题就是：Bagging能够提高弱分类器性能的原因是降低了方差，Boosting 能够提升弱分类器性能的原因是降低了偏差。

**bagging和boosting模型降低方差和偏差的原理**

![](E:\笔记系列\百面机器学习\图片\bagging和boosting模型降低方差和偏差的原理.PNG)

泛化误差、偏差、方差和模型复杂度的关系如图：

![](E:\笔记系列\百面机器学习\图片\偏差方差模型复杂度.PNG)

### GBDT

Gradient Boosting是Boosting中的一大类算法，其基本思想是根据当前模型损失函数的负梯度信息来训练新加入的弱分类器，然后将训练好的弱分类器以累加的形式结合到现有模型中。算法如下：

![](E:\笔记系列\百面机器学习\图片\GB伪代码.PNG)

采用决策树作为弱分类器的算法被称为GBDT

**<font color=red>梯度提升与梯度下降的区别与联系</font>**

以下是梯度提升算法和梯度下降算法的对比情况。可以发现，两者都是在每一轮迭代中，利用损失函数相对于模型的负梯度方向的信息来对当前模型进行更新，只不过在梯度下降中，模型是以参数化形式表示，从而模型的更新等价于参数的更新。而在梯度提升中，模型并不需要进行参数化表示，而是直接定义在函数空间中，从而大大扩展了可以使用的模型种类。

![](E:\笔记系列\百面机器学习\图片\梯度提升与梯度下降比较.PNG)

**<font color=red>GBDT的优缺点</font>**

**<font color=green>优点</font>**

1. 预测阶段的计算速度快，树与树之间可并行化计算。
2. 在分布稠密的数据集上，泛化能力和表达能力都很好，这使得GBDT在Kaggle的众多竞赛中，经常名列榜首。
3. 采用决策树作为弱分类器使得GBDT模型具有较好的解释性和鲁棒性，能够自动发现特征间的高阶关系，并且也不需要对数据进行特殊的预处理如归一化等。

**<font color=green>局限性</font>**

1. GBDT在高维稀疏的数据集上，表现不如支持向量机或者神经网络。
2. GBDT在处理文本分类特征问题上，相对其他模型的优势不如它在处理数值特征时明显。
3. 训练过程需要串行训练，只能在决策树内部采用一些局部并行的手段提高训练速度。

### XGBOOST

xgboost的损失函数

$$L _ { t } = \sum _ { i } l \left( y _ { i } , F _ { t - 1 } \left( x _ { i } \right) + f _ { t } \left( x _ { i } \right) \right) + \Omega \left( f _ { t } \right)$$

$F _ { t - 1 } \left( x _ { i } \right)$表示现有的t-1棵树的最优解，树结构的正则项定义为：

$$\Omega \left( f _ { t } \right) = \gamma T + \frac { 1 } { 2 } \lambda \sum _ { j = 1 } ^ { T } w _ { j } ^ { 2 }$$

其中T为叶子节点个数，$w_j$表示第个叶子节点的预测值。对该损失函数在$F_{t-1}$处进行二阶泰勒展开可以推导出:

$L _ { t } \approx \tilde { L } _ { t } = \sum _ { j = 1 } ^ { T } \left[ G _ { j } w _ { j } + \frac { 1 } { 2 } \left( H _ { j } + \lambda \right) w _ { j } ^ { 2 } \right] + \gamma T$

其中T为决策树，$f_t$中叶子节点的个数，$G _ { j } = \sum _ { i \in I _ { j } } \nabla _ { F _ { t - 1 } } l \left( y _ { i } , F _ { t - 1 } \left( x _ { i } \right) \right)$，$H _ { j } = \sum _ { j \in I _ { j } } \nabla _ { F _ { t - 1 } } ^ { 2 } l \left( y _ { i } , F _ { t - 1 } \left( x _ { i } \right) \right)$，$I_j$表示所有属于叶子节点$j$的样本的索引的结合。

假设决策树的结构已知，通过令损失函数相对于$w_j $的导数为0可以求出在最小化损失函数的情况下各个叶子节点上的预测值

$w _ { j } ^ { * } = - \frac { G _ { j } } { H _ { j } + \lambda }$

然而从所有的树结构中寻找最优的树结构是一个NP-hard问题，因此在实际中往往采用贪心法来构建出一个次优的树结构，基本思想是从根节点开始，每次对一个叶子节点进行分裂，针对每一种可能的分裂，根据特定的准则选取最优的分裂。不同的决策树算法采用不同的准则，如ID3算法采用信息增益，C4.5算法为了克服信息增益中容易偏向取值较多的特征而采用信息增益比，CART算法使用基尼指数和平方误差，XGBoost 也有特定的准则来选取最优分裂。
通过将预测值代入到损失函数中可求得损失函数的最小值

$\tilde { L } _ { t } ^ { * } = - \frac { 1 } { 2 } \sum _ { j = 1 } ^ { T } \frac { G _ { j } ^ { 2 } } { H _ { j } + \lambda } + \gamma T$

容易计算出分裂前后损失函数的差值为

$Gain= \frac { G _ { L } ^ { 2 } } { H _ { L } + \lambda } + \frac { G _ { R } ^ { 2 } } { H _ { R } + \lambda } - \frac { \left( G _ { L } + G _ { R } \right) ^ { 2 } } { H _ { L } + H _ { R } + \lambda } - \gamma$

XGBoost采用最大化这个差值作为准则来进行决策树的构建，通过遍历所有特征的所有取值，寻找使得损失函数前后相差最大时对应的分裂方式。此外，由于损失函数前后存在差值一定为正的限制，此时$\lambda$起到了一定的预剪枝效果。

XGboost和GBDT的**区别与联系**

1. GBDT是机器学习算法，XGBoost是该算法的工程实现。
2. 在使用CART作为基分类器时，XGBoost显式地加入了正则项来控制模型的复杂度，有利于防止过拟合，从而提高模型的泛化能力。
3. GBDT在模型训练时只使用了代价函数的一阶导数信息，XGBoost对代价函数进行二阶泰勒展开，可以同时使用一阶和二阶导数。
4. 传统的GBDT采用CART作为基分类器，XGBoost支持多种类型的基分类器，比如线性分类器。
5. 传统的GBDT在每轮迭代时使用全部的数据，XGBoost则采用了与随机森林相似的策略，支持对数据进行采样。
6. 传统的GBDT没有设计对缺失值进行处理，XGBoost能够自动学习出缺失值的处理策略。